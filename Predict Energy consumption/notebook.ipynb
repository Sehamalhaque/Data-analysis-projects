{"cells":[{"source":"![](imagegeneratedbyai.png)\n\nImagine living in a house where every single watt of electricity you use is meticulously recorded, each of which contributes to a vast pool of data. By analyzing this detailed household power consumption data recorded over nearly 4 years, an energy company can help customers achieve sustainable energy usage while balancing their energy generation. With predictive models, the company can optimize energy usage, forecast future consumption, and provide tailored recommendations. Your task is to use this dataset to build a model that predicts power consumption, benefiting both the energy provider and its customers.\n\n## The Data\n\nAvailable in `df_train.csv` and `df_test.csv`:\n\n| Column             | Type   | Description                                                                 |\n|--------------------|--------|----------------------------------------------------------------------------|\n| date               | chr    | Date of the measurement                                                    |\n| power_consumption  | dbl    | Daily power consumption (in kilowatts)                                     |\n| year               | int    | Year of the measurement                                                    |\n| semester           | int    | Semester of the measurement (1 for Jan-Jun, 2 for Jul-Dec)                 |\n| quarter            | int    | Quarter of the measurement (1 for Q1, 2 for Q2, 3 for Q3, 4 for Q4)        |\n| day_in_week        | chr    | Day of the week of the measurement (e.g., Monday, Tuesday)                 |\n| week_in_year       | int    | Week number in the year of the measurement                                 |\n| day_in_year        | int    | Day number in the year of the measurement                                  |\n| month              | int    | Month of the year of the measurement                                       |\n\nThis dataset was donated to the UCI Machine Learning Repository. For detailed information about the dataset and the preprocessing steps, please refer to the [License and Data Preprocessing Details](License.ipynb) notebook.","metadata":{},"id":"280927ef-5ba5-4769-b121-a8dc5ae5044f","cell_type":"markdown"},{"source":"# Load necessary libraries\nsuppressPackageStartupMessages(library(dplyr))\nlibrary(lubridate) \nlibrary(ranger)    \nlibrary(xgboost)   \nlibrary(ggplot2)   \n\n# Load and inspect the training and testing datasets\ndf_train <- read.csv(\"df_train.csv\")\ndf_test <- read.csv(\"df_test.csv\")\n\n## Explore the structure of the dataset\nglimpse(df_train)\n\n# Load necessary libraries\nlibrary(dplyr)     \nlibrary(lubridate) \nlibrary(ranger)    \nlibrary(xgboost)   \nlibrary(ggplot2)   \n\n# Read training and testing data from CSV files\ndf_train <- read.csv(\"df_train.csv\")\ndf_test <- read.csv(\"df_test.csv\")\n\n# Display structure of the training data\nglimpse(df_train)\n\n# Convert 'date' column to Date type and 'day_in_week' column to factor in both datasets\ndf_train <- df_train %>%\n  mutate(date = as.Date(date, format = \"%m/%d/%Y\"),\n         day_in_week = factor(day_in_week)) \ndf_test <- df_test %>%\n  mutate(date = as.Date(date, format = \"%m/%d/%Y\"),\n         day_in_week = factor(day_in_week))\n\n# Convert categorical variable 'day_in_week' to indicator variables using one-hot encoding in both datasets\ndf_onehot_train <- model.matrix(~ day_in_week - 1, data = df_train) %>%\n  as.data.frame()\ndf_onehot_test <- model.matrix(~ day_in_week - 1, data = df_test) %>%\n  as.data.frame()\n\n# Combine one-hot encoded columns with the original datasets and remove the 'day_in_week' column\ndf_train <- mutate(df_train, df_onehot_train) %>% select(-c(day_in_week))\ndf_test <- mutate(df_test, df_onehot_test) %>% select(-c(day_in_week))\n\n# Separate features and target variable for both training and testing datasets\ntrain_x <- df_train %>% select(-power_consumption, -date)  \ntrain_y <- df_train[[\"power_consumption\"]]  \ntest_x <- df_test %>% select(-power_consumption, -date)  \ntest_y <- df_test[[\"power_consumption\"]]  \n\n# Train models, predict on test dataset and calculate RMSE for each model.\n## Linear regression\nlm_model <- lm(train_y ~ ., data = train_x)   \nlm_pred <- predict(lm_model, newdata = test_x)  \nlm_rmse <- sqrt(mean((test_y - lm_pred)^2))  \n\n## Random forest\nrf_model <- ranger(power_consumption ~., data = df_train %>% select(-date), num.trees = 1000)\nrf_pred <- predict(rf_model, data = df_test %>% select(-date))$predictions  \nrf_rmse <- sqrt(mean((test_y - rf_pred)^2))  \n\n## XGBoost\nxgb_model <- xgboost(\n  data = as.matrix(train_x),  \n  label = train_y,  \n  nrounds = 500, \n  objective = \"reg:squarederror\",  \n  eta = 0.1,  \n  max_depth = 1,  \n  verbose = FALSE\n)\nxgb_pred <- predict(xgb_model, newdata = as.matrix(test_x))  \nxgb_rmse <- sqrt(mean((test_y - xgb_pred)^2))  \n\n# RMSE scores\ndata.frame(\n  Model = c(\"Linear Regression\", \"Random Forest\", \"XGBoost\"),  \n  RMSE = c(lm_rmse, rf_rmse, xgb_rmse)  \n)\n\n# Get the lowest RMSE and assign it to selected_rmse\nselected_rmse <- min(lm_rmse, rf_rmse, xgb_rmse)\ncat(\"selected_rmse:\", selected_rmse, \"kW\\n\")\n\n# Add predictions to the test dataset for plotting\ndf_test <- df_test %>%\n  mutate(Predicted = rf_pred)\n\n# Plot actual vs predicted power consumption over time to check for trend similarity\nggplot(df_test) +\n  geom_line(aes(x = date, y = power_consumption), color = \"green\", linewidth = 1.1) +\n  geom_line(aes(x = date, y = Predicted), color = \"brown\", linewidth = 1) +\n  labs(title = \"Power Consumption: Original and Predicted\", x = \"Date\", y = \"Power Consumption\", caption = \"Green is original and brown is predicted data\") +\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b\") +\n  theme_minimal() +\n  theme(panel.grid.major.x = element_line(color = \"grey80\"))\n\ntrend_similarity <- \"Yes\"\n\ncat(\"trend_similarity:\", trend_similarity, \"\\n\")","metadata":{"executionCancelledAt":null,"executionTime":60,"lastExecutedAt":1744459262604,"lastExecutedByKernel":"1be5db99-6f0f-4f1e-8f47-dec6a8857300","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load necessary libraries\nsuppressPackageStartupMessages(library(dplyr))\nlibrary(lubridate) \nlibrary(ranger)    \nlibrary(xgboost)   \nlibrary(ggplot2)   \n\n# Load and inspect the training and testing datasets\ndf_train <- read.csv(\"df_train.csv\")\ndf_test <- read.csv(\"df_test.csv\")\n\n## Explore the structure of the dataset\nglimpse(df_train)\n\n# Start coding here...add as many cells as you like!\ndf_train$date <- as.Date(df_train$date, format = \"%m/%d/%Y\")\ndf_test$date <- as.Date(df_test$date, format = \"%m/%d/%Y\")\n\n# Convert day_in_week from character to factor\ndf_train$day_in_week <- as.factor(df_train$day_in_week)\ndf_test$day_in_week <- as.factor(df_test$day_in_week)\n\n# Ensure factor levels in test match training\ndf_test$day_in_week <- factor(df_test$day_in_week, levels = levels(df_train$day_in_week))\n\n# Create dummy variables for factor columns\ndummy_encoder <- dummyVars(~ day_in_week, data = df_train)\n\ntrain_dummies <- predict(dummy_encoder, newdata = df_train)\ntest_dummies <- predict(dummy_encoder, newdata = df_test)\n\n# Combine dummy variables with numeric features\nnumeric_features <- c(\"year\", \"semester\", \"quarter\", \"week_in_year\", \"day_in_year\", \"month\")\ntrain_processed <- cbind(df_train[, numeric_features], train_dummies)\ntest_processed <- cbind(df_test[, numeric_features], test_dummies)\n\n# Add target variable\ntrain_processed$power_consumption <- df_train$power_consumption\ntest_processed$power_consumption <- df_test$power_consumption\n\n# Check structure of processed data\nstr(train_processed)\nstr(test_processed)\n\n","outputsMetadata":{"0":{"height":248,"type":"stream"},"1":{"height":251,"type":"stream"},"2":{"height":211,"type":"dataFrame"},"3":{"height":145,"type":"dataFrame"},"4":{"height":59,"type":"stream"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"id":"b723c8f5-f7ee-4d71-882b-b3e85e385fb4","cell_type":"code","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":"Rows: 1,202\nColumns: 9\n$ date              \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"12/16/2006\", \"12/17/2006\", \"12/18/2006\", \"12/19/200…\n$ power_consumption \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 1209.176, 3390.460, 2203.826, 1666.194, 2225.748, 17…\n$ year              \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006…\n$ semester          \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1…\n$ quarter           \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1…\n$ day_in_week       \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Sat\", \"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sa…\n$ week_in_year      \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 50, 51, 51, 51, 51, 51, 51, 51, 52, 52, 52, 52, 52, …\n$ day_in_year       \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 36…\n$ month             \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, …\n"},{"output_type":"error","ename":"ERROR","evalue":"Error in dummyVars(~day_in_week, data = df_train): could not find function \"dummyVars\"\n","traceback":["Error in dummyVars(~day_in_week, data = df_train): could not find function \"dummyVars\"\nTraceback:\n"]}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.2.1"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}